# QR Code Authentication: DetectingOriginal vs. Counterfeit Prints
## Demo:



https://github.com/user-attachments/assets/8268f10d-1109-4fbf-9842-cfc81184c649


## Overview
This project focuses on developing a machine learning model to classify QR codes as either **original (first print)** or **counterfeit (second print)**. The dataset consists of QR codes with embedded **copy detection patterns (CDPs)** that help differentiate between original and reprinted copies. 

## Dataset Description
- **First Prints:** Original QR codes with unique embedded patterns.
- **Second Prints:** Counterfeit copies generated by scanning and reprinting first prints.
- **Challenges:** Differences in print quality, microscopic patterns, and degradation of details in second prints.

## Model Approaches
To achieve high accuracy, multiple models were explored:

### **1. Traditional CNN-Based Models**
- **ResNet, ImageNet, Xception, and InceptionNet** were tested but struggled to surpass **60% accuracy** due to their limited ability to capture subtle print artifacts.

### **2. Vision Transformer (ViT) Approach**
- The **ViT model** was implemented and successfully achieved higher accuracy due to its **self-attention mechanism** and ability to capture **global image structures**.
- Final validation accuracy: **97.5%**

## Training and Evaluation
The model was trained using **PyTorch and timm's Vision Transformer implementation** with the following results:

### **Validation Results**
- **Validation Accuracy:** **97.5%**
- **Confusion Matrix:**
  ```
  [[19  1]
   [ 0 20]]
  ```
- **Precision:** 0.976
- **Recall:** 0.975
- **F1 Score:** 0.9749

#### **Classification Report:**
| Class  | Precision | Recall | F1-Score | Support |
|--------|-----------|--------|----------|---------|
| First Print (Class 0) | 1.00 | 0.95 | 0.97 | 20 |
| Second Print (Class 1) | 0.95 | 1.00 | 0.98 | 20 |
| **Overall Accuracy** | **0.97** | **0.97** | **0.97** | **40** |

## Deployment Considerations
### **1. Deployment Strategy**
- **Model Optimization:** Convert PyTorch model to **.pth** for faster inference.
- **Edge AI Compatibility:** Deploy using streamlit devices for real-time QR authentication.

### **2. Challenges Faced**
- **Low Performance of Traditional CNN Models**
- **Small Dataset and Print Quality Variability**

## Conclusion
This project demonstrates that **Vision Transformers outperform traditional CNN-based models** in QR code authentication. With **97.5% accuracy**, the model shows strong potential for **real-world deployment** in anti-counterfeiting systems. Future work will focus on **improving robustness, optimizing inference speed, and securing the authentication process** for large-scale applications.

## How to Run the Code
1. Clone this repository:
   ```bash
   git clone https://github.com/your-repo/qr-authentication.git
   cd qr-authentication
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
3. Train the model: Run all the cells in `model_development.ipynb` and a model is generated and stored as `vit_model.pth`.

   
4. Run inference on a new QR code(Open in cmd with the main.py file directory):
   ```bash
   streamlit run main.py
   ```
5. Upload an Image: Select the image from your computer and see the magic.
   

